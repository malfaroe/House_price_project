{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import libraries \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# import all libraries and dependencies for data visualization\n",
    "pd.options.display.float_format='{:.4f}'.format\n",
    "plt.rcParams['figure.figsize'] = [8,8]\n",
    "pd.set_option('display.max_columns', 350)\n",
    "pd.set_option('display.max_colwidth', -1) \n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "sns.set(style='darkgrid')\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.ticker as plticker\n",
    "\n",
    "\n",
    "# import all libraries and dependencies for machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import RobustScaler \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LinearRegression, OrthogonalMatchingPursuit, Lasso, LassoLarsIC, ElasticNet, ElasticNetCV\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import f_regression, mutual_info_regression, SelectKBest, RFECV, SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, kurtosis, skew\n",
    "\n",
    "# Import specific libraries\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats import diagnostic as diag\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "\n",
    "\n",
    "# Stats\n",
    "from scipy.stats import skew, norm\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import skew, norm, probplot, boxcox\n",
    "from scipy.special import boxcox1p\n",
    "from patsy import dmatrices\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler, PolynomialFeatures, StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import f_regression, mutual_info_regression, SelectKBest, RFECV, SelectFromModel\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import LinearRegression, OrthogonalMatchingPursuit, Lasso, LassoLarsIC, ElasticNet, ElasticNetCV\n",
    "from sklearn.linear_model import SGDRegressor, PassiveAggressiveRegressor, HuberRegressor, BayesianRidge\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, BaggingRegressor, ExtraTreesRegressor\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor, plot_importance\n",
    "import lightgbm as lgb\n",
    "\n",
    "from patsy import dmatrices\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, cross_val_predict, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "pd.set_option('expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading datasets\n",
    "\n",
    "%store -r all_data\n",
    "%store -r y_train\n",
    "\n",
    "\n",
    "#Loading sets de features obtenidos en la etapa de Feature Selection\n",
    "%store -r pv_cols\n",
    "%store -r sel_cols_rfecv\n",
    "%store -r SBS\n",
    "%store -r kbest_FR\n",
    "%store -r kbest_MIR\n",
    "%store -r Xgb_selected_feats\n",
    "%store -r total_cols\n",
    "\n",
    "#Loading polynomial_features dataframe\n",
    "%store -r new_poly_features\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1449, 190)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###ACTUALIZACION DE TRAIN Y TEST ANTES DE PASAR A MODELING\n",
    "\n",
    "# #Creo el train y se resetea también su index\n",
    "train = all_data.round(3).iloc[:len(y_train), :]\n",
    "train = train.loc[:, list(total_cols)].reset_index(drop = True, inplace = False)\n",
    "\n",
    "# #Creo el test y se resetea también su index\n",
    "test = all_data.round(3).iloc[len(y_train):, :]\n",
    "test= test.loc[:, list(total_cols)].reset_index(drop = True, inplace = False)\n",
    "\n",
    "# #Reseteo además el y_train en su index\n",
    "\n",
    "y_train = y_train.reset_index(drop = True, inplace = False)\n",
    "\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####DIMENSIONALITY REDUCTION VIA PRINCIPAL COMPONENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Excelente explicación en este link: https://www.youtube.com/watch?v=AniiwysJ-2Y&list=PLs8w1Cdi-zvZ43xD_AA-eAuEW1FLK0cef&index=6'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Excelente explicación en este link: https://www.youtube.com/watch?v=AniiwysJ-2Y&list=PLs8w1Cdi-zvZ43xD_AA-eAuEW1FLK0cef&index=6\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With only 120 features: 99.8725% of the variance was captured \n",
      "\n",
      "After PCA, 120 features only left not explained 0.1275% of variance ratio from the original 190\n"
     ]
    }
   ],
   "source": [
    "#Haremos una reducción dimensional de la data utilizando  PCA:\n",
    "#Escalamos los datos: es un requisito antes de aplicar PCA\n",
    "scale = RobustScaler() \n",
    "df = scale.fit_transform(train)\n",
    "\n",
    "pca = PCA().fit(df) # whiten=True\n",
    "\n",
    "print('With only 120 features: {:6.4%} of the variance was captured'.format(sum(pca.explained_variance_ratio_[:120])),\"\\n\")\n",
    "\n",
    "print('After PCA, {:3} features only left not explained {:6.4%} of variance ratio from the original {:3}'.format(120,\n",
    "                                                                                    (sum(pca.explained_variance_ratio_[120:])),\n",
    "                                                                                    df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9987252226760344"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pca.explained_variance_ratio_[:120])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nota: el número de features seleccionados fue elegido a criterio. Uno puede elegir seteando pca en n_components_ = m, lo que arrojará\\nlos m mejores componentes proyectados. En este caso se dejó m = 190 pero se cortó en 120 para mostrar que con 120 ya se tenía\\nel 99.9% de la varianza explicada (es decir, se captura el 99.9% de la información de los datos originales)'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Nota: el número de features seleccionados fue elegido a criterio. Uno puede elegir seteando pca en n_components_ = m, lo que arrojará\n",
    "los m mejores componentes proyectados. En este caso se dejó m = 190 pero se cortó en 120 para mostrar que con 120 ya se tenía\n",
    "el 99.9% de la varianza explicada (es decir, se captura el 99.9% de la información de los datos originales)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class select_fetaures(object): # BaseEstimator, TransformerMixin, \n",
    "    def __init__(self, select_cols):\n",
    "        self.select_cols_ = select_cols\n",
    "\n",
    "    def fit(self, X, Y ):\n",
    "        print('Received {0:2d} features...'.format(X.shape[1]))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        print('Select {0:2d} features'.format(X.loc[:, self.select_cols_].shape[1]))\n",
    "        return X.loc[:, self.select_cols_]    \n",
    "\n",
    "    def fit_transform(self, X, Y):\n",
    "        self.fit(X, Y)\n",
    "        df = self.transform(X)\n",
    "        return df \n",
    "        #X.loc[:, self.select_cols_]    \n",
    "\n",
    "    def __getitem__(self, x):\n",
    "        return self.X[x], self.Y[x]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(model, name='NAN', log=False):\n",
    "    \n",
    "    rcols = ['Name','Model', 'BestParameters', 'Scorer', 'Index', 'BestScore', 'BestScoreStd', 'MeanScore', \n",
    "             'MeanScoreStd', 'Best']\n",
    "    res = pd.DataFrame(columns=rcols)\n",
    "    results = gs.cv_results_\n",
    "    modelo = gs.best_estimator_\n",
    "\n",
    "    scoring = {'MAE': 'neg_mean_absolute_error', 'R2': 'r2', 'RMSE': 'neg_mean_squared_error'}\n",
    "\n",
    "    for scorer in sorted(scoring):\n",
    "        best_index = np.nonzero(results['rank_test_%s' % scoring[scorer]] == 1)[0][0]\n",
    "        if scorer == 'RMSE': \n",
    "            best = np.sqrt(-results['mean_test_%s' % scoring[scorer]][best_index])\n",
    "            best_std = np.sqrt(results['std_test_%s' % scoring[scorer]][best_index])\n",
    "            scormean = np.sqrt(-results['mean_test_%s' % scoring[scorer]].mean())\n",
    "            stdmean = np.sqrt(results['std_test_%s' % scoring[scorer]].mean())\n",
    "            if log:\n",
    "                best = np.expm1(best)\n",
    "                best_std = np.expm1(best_std)\n",
    "                scormean = np.expm1(scormean)\n",
    "                stdmean = np.expm1(stdmean)\n",
    "        elif scorer == 'MEA':\n",
    "            best = (-results['mean_test_%s' % scoring[scorer]][best_index])\n",
    "            best_std = results['std_test_%s' % scoring[scorer]][best_index]\n",
    "            scormean =(-results['mean_test_%s' % scoring[scorer]].mean())\n",
    "            stdmean = results['std_test_%s' % scoring[scorer]].mean()\n",
    "            if log:\n",
    "                best = np.expm1(best)\n",
    "                best_std = np.expm1(best_std)\n",
    "                scormean = np.expm1(scormean)\n",
    "                stdmean = np.expm1(stdmean)\n",
    "        else:\n",
    "            best = results['mean_test_%s' % scoring[scorer]][best_index]*100\n",
    "            best_std = results['std_test_%s' % scoring[scorer]][best_index]*100\n",
    "            scormean = results['mean_test_%s' % scoring[scorer]].mean()*100\n",
    "            stdmean = results['std_test_%s' % scoring[scorer]].mean()*100\n",
    "        \n",
    "        r1 = pd.DataFrame([(name, modelo, gs.best_params_, scorer, best_index, best, best_std, scormean, \n",
    "                            stdmean, gs.best_score_)],\n",
    "                          columns = rcols)\n",
    "        res = res.append(r1)\n",
    "        \n",
    "    if log:\n",
    "        bestscore = np.expm1(np.sqrt(-gs.best_score_))\n",
    "    else:\n",
    "        bestscore = np.sqrt(-gs.best_score_)\n",
    "        \n",
    "    print(\"Best Score: {:.6f}\".format(bestscore))\n",
    "    print('---------------------------------------')\n",
    "    print('Best Parameters:')\n",
    "    print(gs.best_params_)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received 190 features...\n",
      "Select 109 features\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  68 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=4)]: Done 1260 tasks      | elapsed:    7.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.116419\n",
      "---------------------------------------\n",
      "Best Parameters:\n",
      "{'model__alpha': 0.0007, 'model__max_iter': 5, 'model__selection': 'cyclic', 'model__tol': 0.002, 'pca__n_components': 106, 'pca__whiten': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 1440 out of 1440 | elapsed:    8.3s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scorer</th>\n",
       "      <th>Index</th>\n",
       "      <th>BestScore</th>\n",
       "      <th>BestScoreStd</th>\n",
       "      <th>MeanScore</th>\n",
       "      <th>MeanScoreStd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAE</td>\n",
       "      <td>75</td>\n",
       "      <td>-7.7109</td>\n",
       "      <td>0.2878</td>\n",
       "      <td>-14.2141</td>\n",
       "      <td>0.5693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R2</td>\n",
       "      <td>51</td>\n",
       "      <td>92.3635</td>\n",
       "      <td>0.2231</td>\n",
       "      <td>69.2846</td>\n",
       "      <td>0.7427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>75</td>\n",
       "      <td>0.1164</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.2474</td>\n",
       "      <td>0.0649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Scorer Index  BestScore  BestScoreStd  MeanScore  MeanScoreStd\n",
       "0  MAE    75   -7.7109    0.2878        -14.2141   0.5693       \n",
       "0  R2     51   92.3635    0.2231        69.2846    0.7427       \n",
       "0  RMSE   75   0.1164     0.0262        0.2474     0.0649       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'residuals_plots' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-3d26756c865a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlasso\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lasso Lg1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Scorer'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;34m'MeanScoreStd'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresiduals_plots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlasso\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'residuals_plots' is not defined"
     ]
    }
   ],
   "source": [
    "model = Pipeline([\n",
    "        ('pca', PCA(random_state = 101)),\n",
    "        ('model', Lasso(random_state = 101))]) \n",
    "\n",
    "SEL = list(set(sel_cols_rfecv).union(set(new_poly_features.columns)))\n",
    "n_components = [len(SEL)-5, len(SEL)-3, len(SEL)] \n",
    "whiten = [False, True]\n",
    "max_iter = [5] #, 10, 100, 200, 300, 400, 500, 600]  \n",
    "alpha = [0.0003, 0.0007, 0.0005, 0.05, 0.5, 1.0]\n",
    "selection = ['random', 'cyclic'] \n",
    "tol = [2e-03, 0.003, 0.001, 0.0005]\n",
    "param_grid =\\\n",
    "            dict(\n",
    "                  model__alpha = alpha\n",
    "                  ,model__max_iter = max_iter\n",
    "                  ,model__selection = selection\n",
    "                  ,model__tol = tol\n",
    "                  ,pca__n_components = n_components\n",
    "                  ,pca__whiten = whiten \n",
    "                ) \n",
    "\n",
    "gs = GridSearchCV(estimator = model, param_grid = param_grid, refit = 'neg_mean_squared_error' #, iid=False\n",
    "                   , scoring=list(['neg_mean_squared_error' , 'neg_mean_absolute_error', 'r2']) \n",
    "                   ,cv=5, verbose=1, n_jobs=4)\n",
    "\n",
    "lasso = Pipeline([\n",
    "        ('sel', select_fetaures(select_cols=SEL)), \n",
    "        ('scl', RobustScaler()),\n",
    "        ('gs', gs)\n",
    " ])\n",
    "\n",
    "lasso.fit(train,y_train)\n",
    "\n",
    "results = get_results(lasso, 'lasso Lg1', log=True)\n",
    "display(results.loc[:, 'Scorer' : 'MeanScoreStd'])\n",
    "r = residuals_plots(lasso, train, y_train, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
